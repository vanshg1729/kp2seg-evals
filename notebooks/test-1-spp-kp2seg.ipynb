{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home2/rjayanti/workdirs/rjayanti/kp2seg-evals\n",
      "/scratch/toponav/indoor-topo-loc/checkpoints/torchhub\n"
     ]
    }
   ],
   "source": [
    "# reload notebook automatically after changes to source python files\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# change base folder to parent\n",
    "import os\n",
    "if os.path.basename(os.getcwd()) == 'notebooks':\n",
    "    os.chdir('..')\n",
    "print(os.getcwd())\n",
    "\n",
    "import torch\n",
    "torch.hub.set_dir('/scratch/toponav/indoor-topo-loc/checkpoints/torchhub')\n",
    "print(torch.hub.get_dir())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available scenes: len=176\n",
      "Selected scenes: len=3\n",
      "Avaliable scenes: ['036bce3393', '076c822ecc', '079a326597', '07f5b601ee', '07ff1c45bb', '08bbbdcc3d', '09bced689e', '0a184cf634', '0a5c013435', '0a7cc12c0e', '0b031f3119', '104acbf7d2', '108ec0b806', '116456116b', '1204e08f17', '1366d5ae89', '16c9bd2e1e', '1a130d092a', '1a8e0d78c0', '1ae9e5d2a6', '1b75758486', '1b9692f0c7', '1c4b893630', '1f7cbbdde1', '210f741378', '251443268c', '25927bb04c', '260db9cf5a', '260fa55d50', '281bc17764', '28a9ee4557', '2970e95b65', '2a496183e1', '2b1dc6d6a5', '2e74812d00', '302a7f6b67', '303745abc7', '30966f4c6e', '30f4a2b44d', '320c3af000', '32280ecbca', '324d07a5b3', '37ea1c52f0', '3928249b53', '394a542a19', '39e6ee46df', '39f36da05b', '3e928dc2f6', '3f1e1610de', '40b56bf310', '419cbe7c11', '41b00feddb', '4422722c49', '45d2e33be1', '47b37eb6f9', '480ddaadc0', '4a1a3a7dc5', '4ba22fa7e4', '4c5c60fa76', '4ea827f5a1', '50809ea0d8', '52599ae063', '55b2bf8036', '5654092cc2', '56a0ec536c', '59e3f1ea37', '5a269ba6fe', '5d152fab1b', '61adeff7d5', '646af5e14b', '66c98f4a9b', '67d702f2e8', '6855e1ac32', '689fec23d7', '69e5939669', '6cc2231b9c', '6d89a7320d', '6ee2fc1070', '7079b59642', '712dc47104', '75d29d69b8', '7977624358', '7e09430da7', '7e7cd69a59', '7eac902fd5', '80ffca8a48', '8133208cb6', '824d9cfa6e', '85251de7d1', '87f6d7d564', '88627b561e', '88cf747085', '893fb90e89', '8a35ef3cfe', '8b2c0938d6', '8b5caf3398', '8be0cd3817', '8d563fc2cc', '8e00ac7f59', '8e6ff28354', '9471b8d485', '94ee15e8ba', '9859de300f', '98b4ec142f', '98fe276aa8', '9f139a318d', '9f21bdec45', '9f79564dbf', 'a003a6585e', 'a05ee63164', 'a08dda47a8', 'a1d9da703c', 'a29cccc784', 'aaa11940d3', 'ab046f8faf', 'ab6983ae6c', 'acd69a1746', 'ad2d07fd11', 'ada5304e41', 'b08a908f0f', 'b09431c547', 'b1d75ecd55', 'b20a261fdf', 'b5918e4637', 'b73f5cdc41', 'b97261909e', 'bb87c292ad', 'bc03d88fc3', 'bc2fce1d81', 'bc400d86e1', 'bd9305480d', 'be0ed6b33c', 'bf6e439e38', 'bfd3fd54d2', 'c06a983e63', 'c0c863b72d', 'c0f5742640', 'c173f62b15', 'c24f94007b', 'c545851c4f', 'c856c41c99', 'c8f2218ee2', 'c9abde4c4b', 'ccfd3ed9c7', 'cf1ffd871d', 'd2f44bf242', 'd415cc449b', 'd6702c681d', 'd6d9ddb03f', 'daffc70503', 'dc263dfbf0', 'dfac5b38df', 'e01b287af5', 'e0abd740ba', 'e0de253456', 'e1b1d9de55', 'e3ecd49e2b', 'e7ac609391', 'e898c76c1f', 'e8e81396b6', 'e8ea9b4da8', 'ebc200e928', 'ed2216380b', 'ef18cf0708', 'ef25276c25', 'ef69d58016', 'f07340dfea', 'f248c2bcdc', 'f25f5e6f63', 'f34d532901', 'f5401524e5', 'f8062cb7ce', 'f8f12e4e6b', 'fb05e13ad1', 'fd361ab85f', 'fe1733741f']\n",
      "Selected scenes: len=3\n",
      "Total ref-query pairs: 16063\n",
      "Length of Val DataLoader: len(val_loader) = 16063\n"
     ]
    }
   ],
   "source": [
    "from configs.default import cfg\n",
    "\n",
    "eval_spp_config = 'configs/config_eval_spp_resz.yaml'\n",
    "cfg.merge_from_file(eval_spp_config)\n",
    "\n",
    "from src.datasets.scannetpp_resz_hard_iou_eval_interface import ScanNetPPResizedHardIoUDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "val_selected_scenes = [\"394a542a19\", \"9f79564dbf\", \"e8e81396b6\"]\n",
    "\n",
    "val_dataset = ScanNetPPResizedHardIoUDataset(cfg, val_selected_scenes, None)\n",
    "\n",
    "# NOTE: Currently dataset only supports batch size of 1 - to allow for variable number of masks\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=1,\n",
    "    num_workers=cfg.TRAINING.NUM_WORKERS,\n",
    "    drop_last=False,  # Necessary for evaluation\n",
    "    prefetch_factor=cfg.TRAINING.PREFETCH_FACTOR,\n",
    ")\n",
    "print(f\"Length of Val DataLoader: {len(val_loader) = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/rjayanti/workdirs/rjayanti/image-matching-models/matching/third_party/LightGlue/lightglue/lightglue.py:24: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_fwd(cast_inputs=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"/home2/rjayanti/workdirs/rjayanti/image-matching-models\")\n",
    "\n",
    "from matching import get_matcher\n",
    "\n",
    "device = 'cuda'\n",
    "MATCHER = 'superpoint-lg' # 'tiny-roma' or 'tiny-roma-4096'\n",
    "matcher = get_matcher(MATCHER, device=device, max_num_keypoints=1024) #TODO change to 4096+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "def compute_vote_matrix(matched_kpts0, matched_kpts1, masks0, masks1):\n",
    "    matched_kpts0 = torch.from_numpy(matched_kpts0) if isinstance(matched_kpts0, np.ndarray) else matched_kpts0\n",
    "    matched_kpts1 = torch.from_numpy(matched_kpts1) if isinstance(matched_kpts1, np.ndarray) else matched_kpts1\n",
    "\n",
    "    K = matched_kpts0.shape[0]\n",
    "    M, H, W = masks0.shape\n",
    "    N = masks1.shape[0]\n",
    "\n",
    "    x0 = matched_kpts0[:, 0].long().clamp(0, W - 1)\n",
    "    y0 = matched_kpts0[:, 1].long().clamp(0, H - 1)\n",
    "    x1 = matched_kpts1[:, 0].long().clamp(0, W - 1)\n",
    "    y1 = matched_kpts1[:, 1].long().clamp(0, H - 1)\n",
    "\n",
    "\n",
    "    src_mask_ids = masks0[:, y0, x0].T  # (K, M)\n",
    "    tgt_mask_ids = masks1[:, y1, x1].T  # (K, N)\n",
    "\n",
    "    valid = src_mask_ids.any(dim=1) & tgt_mask_ids.any(dim=1)\n",
    "    src_idx = src_mask_ids[valid].int().argmax(dim=1)\n",
    "    tgt_idx = tgt_mask_ids[valid].int().argmax(dim=1)\n",
    "\n",
    "    votes = torch.zeros((M, N), dtype=torch.int32)\n",
    "    for i, j in zip(src_idx.tolist(), tgt_idx.tolist()):\n",
    "        votes[i, j] += 1\n",
    "    return votes\n",
    "\n",
    "def get_pred_assignment(votes):\n",
    "    pred = votes.argmax(dim=1)\n",
    "    pred[votes.sum(dim=1) == 0] = -1\n",
    "    return pred\n",
    "\n",
    "def compute_iou(pred_assignment, gt_assignment):\n",
    "    M, N = gt_assignment.shape\n",
    "    gt_idx = gt_assignment.argmax(dim=1)\n",
    "    has_gt = gt_assignment.sum(dim=1) > 0\n",
    "\n",
    "    ious = []\n",
    "    for i in range(M):\n",
    "        if not has_gt[i] and pred_assignment[i] == -1:\n",
    "            ious.append(1.0)\n",
    "        elif has_gt[i] and pred_assignment[i] == gt_idx[i]:\n",
    "            ious.append(1.0)\n",
    "        else:\n",
    "            ious.append(0.0)\n",
    "    return float(np.mean(ious)) if ious else 0.0\n",
    "\n",
    "def evaluate_all(loader, matcher, output_json_path):\n",
    "    results = defaultdict(dict)\n",
    "\n",
    "    for batch in tqdm(loader, desc=\"Evaluating\"):\n",
    "        scene_id = batch[\"scene_id\"][0]\n",
    "        frame0 = batch[\"img0_name\"][0]\n",
    "        frame1 = batch[\"img1_name\"][0]\n",
    "        key = f\"{frame0}_{frame1}\"\n",
    "\n",
    "        img0 = matcher.load_image(str(batch[\"img0_path\"][0]))\n",
    "        img1 = matcher.load_image(str(batch[\"img1_path\"][0]))\n",
    "        result = matcher(img0, img1)\n",
    "\n",
    "        kpts0 = result[\"matched_kpts0\"]\n",
    "        kpts1 = result[\"matched_kpts1\"]\n",
    "        masks0 = batch[\"masks_gt_0\"][0].bool()\n",
    "        masks1 = batch[\"masks_gt_1\"][0].bool()\n",
    "        gt_assignment = torch.diag_embed(batch[\"seg_corr_list_common\"][0])\n",
    "\n",
    "        votes = compute_vote_matrix(kpts0, kpts1, masks0, masks1)\n",
    "        pred_assignment = get_pred_assignment(votes)\n",
    "        avg_iou = compute_iou(pred_assignment, gt_assignment)\n",
    "\n",
    "        results[scene_id][key] = avg_iou\n",
    "\n",
    "    with open(output_json_path, \"w\") as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = evaluate_all(val_loader, matcher, output_json_path=f\"results/{MATCHER}_val_just3.json\")\n",
    "print(\"Done evaluating all pairs.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mast3r",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
